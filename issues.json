[{"body":"## Summary\n\nAdd a custom fields feature to the drivers table, following the same pattern that was implemented for the locations and vehicles tables. This will enable users to define and manage custom metadata fields for drivers through the Settings UI.\n\n## Goals\n\n- Add custom field configuration capability to drivers\n- Mirror the implementation pattern from locations/vehicles tables\n- Update the Data tab in Settings page to support driver custom fields\n- Enable/disable custom fields per use case\n- Provide UI for managing custom field definitions\n\n## Background\n\nThe locations and vehicles tables already have custom fields implementations that allow users to:\n- Define custom field schemas\n- Store custom data in the `metadata` JSONB column\n- Configure fields through the Settings UI Data tab\n\n**Reference Implementations:**\n- Locations: `fleetillo.locations` table has `metadata JSONB` column (see migration `20260122000000_add_data_import_schema_enhancements.sql`)\n- Vehicles: Similar pattern (#144)\n- Pattern: JSONB column with GIN index for efficient queries\n\n## Requirements\n\n### Database Layer\n- [ ] Drivers table already has or needs `metadata JSONB` column\n- [ ] Add GIN index on metadata column if not present\n- [ ] Follow same pattern as locations/vehicles metadata storage\n\n### Settings Configuration\n- [ ] Add driver custom fields configuration to Settings Data tab\n- [ ] UI to define custom field schemas:\n  - Field name\n  - Field type (text, number, boolean, date, select)\n  - Required/optional\n  - Default value\n  - Validation rules\n- [ ] Enable/disable individual fields\n- [ ] Save field definitions to settings table\n\n### Driver Management UI\n- [ ] Display custom fields in driver detail/edit forms\n- [ ] Render fields based on configured schema\n- [ ] Validate input based on field definitions\n- [ ] Store custom data in driver.metadata JSONB column\n\n### API Layer\n- [ ] Driver CRUD operations handle metadata field\n- [ ] Validation against custom field schema\n- [ ] Query support for custom fields (JSONB queries)\n\n## Acceptance Criteria\n\n1. Admin can define custom driver fields in Settings → Data tab\n2. Custom fields appear in driver create/edit forms\n3. Custom field data is stored in drivers.metadata JSONB column\n4. Custom fields can be queried efficiently (GIN index)\n5. Pattern matches locations/vehicles custom fields implementation\n6. Settings UI follows existing design patterns\n\n## Technical Notes\n\n**Existing Pattern (Locations/Vehicles):**\n```sql\n-- From locations table\nALTER TABLE fleetillo.locations\nADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}'::jsonb;\n\nCREATE INDEX IF NOT EXISTS idx_locations_metadata\nON fleetillo.locations USING GIN(metadata);\n```\n\n**Expected Pattern (Drivers):**\n```sql\n-- Similar for drivers table\nALTER TABLE fleetillo.drivers\nADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}'::jsonb;\n\nCREATE INDEX IF NOT EXISTS idx_drivers_metadata\nON fleetillo.drivers USING GIN(metadata);\n```\n\n**Settings Storage:**\nCustom field definitions should be stored in the settings table, similar to other configuration.\n\n**Setting Key:**\n- Add `DRIVERS_CUSTOM_FIELDS: 'drivers.customFields'` to `src/types/settings.ts`\n\n## Use Cases for Driver Custom Fields\n\nExample custom fields that might be useful:\n- Employee ID\n- Certification numbers\n- Emergency contact information\n- Shift preferences\n- Team/region assignment\n- Performance metrics\n- Training completion dates\n- Uniform sizes\n- Preferred vehicle types\n\n## Related\n\n- See #144 for vehicles custom fields implementation (similar pattern)\n- See `20260122000000_add_data_import_schema_enhancements.sql` for locations metadata pattern\n- See Settings Data tab for existing custom field UI patterns\n- Driver type already has `tags` field for categorization\n\n---\n\n**Context:**\n- Branch: main\n- Pattern: Following locations and vehicles table implementations\n- Related: #144 (vehicles custom fields)\n- Created via `/open-issue` command\n","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":145,"title":"Add custom fields to drivers table with Settings UI configuration"},{"body":"## Summary\n\nAdd a custom fields feature to the vehicles table, following the same pattern that was implemented for the locations table. This will enable users to define and manage custom metadata fields for vehicles through the Settings UI.\n\n## Goals\n\n- Add custom field configuration capability to vehicles\n- Mirror the implementation pattern from locations table\n- Update the Data tab in Settings page to support vehicle custom fields\n- Enable/disable custom fields per use case\n- Provide UI for managing custom field definitions\n\n## Background\n\nThe locations table already has a custom fields implementation that allows users to:\n- Define custom field schemas\n- Store custom data in the `metadata` JSONB column\n- Configure fields through the Settings UI Data tab\n\n**Reference Implementation:**\n- Database: `fleetillo.locations` table has `metadata JSONB` column (see migration `20260122000000_add_data_import_schema_enhancements.sql`)\n- Pattern: JSONB column with GIN index for efficient queries\n\n## Requirements\n\n### Database Layer\n- [ ] Vehicles table already has or needs `metadata JSONB` column\n- [ ] Add GIN index on metadata column if not present\n- [ ] Follow same pattern as locations metadata storage\n\n### Settings Configuration\n- [ ] Add vehicle custom fields configuration to Settings Data tab\n- [ ] UI to define custom field schemas:\n  - Field name\n  - Field type (text, number, boolean, date, select)\n  - Required/optional\n  - Default value\n  - Validation rules\n- [ ] Enable/disable individual fields\n- [ ] Save field definitions to settings table\n\n### Vehicle Management UI\n- [ ] Display custom fields in vehicle detail/edit forms\n- [ ] Render fields based on configured schema\n- [ ] Validate input based on field definitions\n- [ ] Store custom data in vehicle.metadata JSONB column\n\n### API Layer\n- [ ] Vehicle CRUD operations handle metadata field\n- [ ] Validation against custom field schema\n- [ ] Query support for custom fields (JSONB queries)\n\n## Acceptance Criteria\n\n1. Admin can define custom vehicle fields in Settings → Data tab\n2. Custom fields appear in vehicle create/edit forms\n3. Custom field data is stored in vehicles.metadata JSONB column\n4. Custom fields can be queried efficiently (GIN index)\n5. Pattern matches locations custom fields implementation\n6. Settings UI follows existing design patterns\n\n## Technical Notes\n\n**Existing Pattern (Locations):**\n```sql\n-- From locations table\nALTER TABLE fleetillo.locations\nADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}'::jsonb;\n\nCREATE INDEX IF NOT EXISTS idx_locations_metadata\nON fleetillo.locations USING GIN(metadata);\n```\n\n**Expected Pattern (Vehicles):**\n```sql\n-- Similar for vehicles table\nALTER TABLE fleetillo.vehicles\nADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}'::jsonb;\n\nCREATE INDEX IF NOT EXISTS idx_vehicles_metadata\nON fleetillo.vehicles USING GIN(metadata);\n```\n\n**Settings Storage:**\nCustom field definitions should be stored in the settings table, similar to other configuration.\n\n## Related\n\n- See `20260122000000_add_data_import_schema_enhancements.sql` for locations metadata pattern\n- See Settings Data tab for existing custom field UI patterns\n\n---\n\n**Context:**\n- Branch: main\n- Pattern: Following locations table implementation\n- Created via `/open-issue` command\n","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":144,"title":"Add custom fields to vehicles table with Settings UI configuration"},{"body":"## Summary\n\nAdd generic telemetry provider integration to enable comparison of planned routes against actual vehicle tracking data from third-party systems (Samsara, Geotab, Verizon Connect, etc.).\n\n## Goals\n\n- **Push** planned routes to telemetry providers for execution tracking\n- **Pull** actual telemetry data (GPS tracks, timestamps, driver behavior)\n- **Compare** planned vs. actual performance metrics\n- **Analyze** route optimization effectiveness and driver efficiency\n\n## Approach\n\nUse a **generic, provider-agnostic architecture** following the existing Fleetillo pattern of using `metadata JSONB` columns (same as locations table) rather than creating provider-specific database tables.\n\n### Key Design Principles\n\n✅ **Generic & Flexible** - Support multiple telemetry providers simultaneously\n✅ **Minimal Schema Changes** - Add metadata columns to vehicles, drivers, and routes tables\n✅ **No Over-Engineering** - Keep Fleetillo clean and not customized for any specific third-party integration\n✅ **Pluggable Architecture** - Abstract provider interface with concrete implementations\n✅ **Future-Proof** - Easy to add new providers without schema changes\n\n## Pre-Plan Strategy Document\n\nSee **[docs/telemetry-integration-strategy.md](docs/telemetry-integration-strategy.md)** for comprehensive strategy including:\n- Database schema design\n- Metadata structure examples\n- Service layer architecture\n- API endpoint design\n- Route lifecycle workflows\n- Analytics computation approach\n- Example JSONB queries\n\n## High-Level Implementation Phases\n\n1. **Foundation** - Database migrations, type definitions, base abstractions\n2. **Provider Implementation** - Samsara provider (initial), others later\n3. **Route Synchronization** - Push/pull routes, telemetry data\n4. **Analytics** - Compute comparison metrics, efficiency scores\n5. **UI** - Settings, metadata management, visualization dashboard\n6. **Testing** - Unit, integration, E2E tests\n\n## Success Metrics\n\n- Route adherence %\n- Time/distance efficiency variance\n- Driver performance scores\n- Cost accuracy improvements\n- Week-over-week optimization gains\n\n## Next Steps\n\n1. ✅ Pre-planning strategy complete (see referenced document)\n2. ⏳ Detailed implementation planning (will occur in future session with `/plan-check`)\n3. ⏳ Execute implementation in phases\n4. ⏳ Iterate based on real-world usage\n\n---\n\n**Context:**\n- Branch: main\n- Created via `/open-issue` command\n\n**Note:** This issue is created for future implementation. The strategy document should be referenced during the planning phase.\n","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"number":143,"title":"Telemetry Integration - Generic provider support for route optimization validation"},{"body":"## Summary\n\nWhen dispatch-service runs in embedded mode, the security headers (helmet) and hardened CORS configuration from the dispatch-service's standalone mode are not applied. These are app-level middleware that should be configured in the web-launcher.\n\n## Current State\n\n- **web-launcher/server.js** uses permissive CORS: `app.use(cors())`\n- No helmet security headers are configured\n- Dispatch routes inherit the web-launcher's permissive settings\n\n## Recommended Changes\n\n### 1. Add Helmet\n```javascript\nconst helmet = require('helmet');\n\napp.use(\n  helmet({\n    contentSecurityPolicy: {\n      directives: {\n        defaultSrc: [\"'self'\"],\n        scriptSrc: [\"'self'\"],\n        styleSrc: [\"'self'\", \"'unsafe-inline'\"],\n        imgSrc: [\"'self'\", 'data:', 'https:'],\n        connectSrc: [\"'self'\"],\n        fontSrc: [\"'self'\"],\n        objectSrc: [\"'none'\"],\n        mediaSrc: [\"'self'\"],\n        frameSrc: [\"'none'\"],\n      },\n    },\n    crossOriginEmbedderPolicy: false,\n  })\n);\n```\n\n### 2. Harden CORS\n```javascript\nconst corsOrigins = process.env.CORS_ORIGIN\n  ? process.env.CORS_ORIGIN.split(',').map((origin) => origin.trim()).filter(Boolean)\n  : [];\n\napp.use(cors({\n  origin: corsOrigins.length > 0 ? corsOrigins : (process.env.NODE_ENV === 'development' ? '*' : false),\n  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],\n  allowedHeaders: ['Content-Type', 'Authorization', 'X-API-Key', 'X-Correlation-ID'],\n}));\n```\n\n## Related\n\n- Follows up on #104 (dispatch service security hardening)\n- Ensures consistent security posture between standalone and embedded dispatch modes\n\n## Priority\n\nMedium - The core security features (auth, rate limiting, validation) already work in embedded mode. This addresses defense-in-depth headers.","labels":[],"number":136,"title":"Security: Add helmet and harden CORS in web-launcher for embedded dispatch mode"},{"body":"In the calendar it needs to display the hours for the day that are configured in the settings work schedule.","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":124,"title":"Display configured work schedule hours in calendar"},{"body":"## Description\nRename the `APP_BASE_URL` environment variable to `ROUTEMAP_DISPATCH_URL` to better describe its purpose.\n\n## Context\nThe `APP_BASE_URL` variable is used specifically for:\n1. Dispatch service calling the route-tokens API internally\n2. Constructing tokenized URLs for the driver route map page\n\nThe current name is generic and confusing. A more descriptive name will prevent future misconfiguration.\n\n## Files to Update\n- `web-launcher/server.js` - line 832\n- `dispatch-service/src/core/templates.ts` - lines 343, 409\n- `dispatch-service/.env.example` - line 8\n- `do-app-spec.yaml` - lines 40, 97\n\n## Post-Deploy Action\nAfter deploying the code changes, rename the env var in DigitalOcean dashboard from `APP_BASE_URL` to `ROUTEMAP_DISPATCH_URL`.\n\n---\n*Issue created via `/open-issue` command*","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVTPbYw","name":"plan: simple","description":"Simple - no plan needed, ready to implement","color":"0E8A16"}],"number":123,"title":"Rename APP_BASE_URL to ROUTEMAP_DISPATCH_URL for clarity"},{"body":"## Description\n\nThe UI saves vehicle home locations to the `vehicle_locations` table with `is_primary=true`, but some backend services read from `vehicles.home_location_id` column which is never updated by the UI. This causes data inconsistency.\n\n## Problem\n\n- **UI saves to**: `vehicle_locations` table with `is_primary=true`\n- **Clustering reads from**: `vehicles.home_location_id` (never updated)\n- **Impact**: Route planning clustering fails for vehicles whose location was set via the UI\n\n## Root Cause\n\nThe `vehicle_locations` junction table was added as the source of truth for vehicle locations, but the legacy `vehicles.home_location_id` column was never deprecated or kept in sync.\n\n## Current Workaround\n\nThe route-planning service was patched to read from `vehicle_locations` table, but this is a localized fix. Other code may still rely on the legacy column.\n\n## Proposed Solution\n\n**Option A (Recommended): Sync on save**\n- When saving to `vehicle_locations` with `is_primary=true`, also update `vehicles.home_location_id`\n- Ensures backwards compatibility with any code using the old column\n\n**Option B: Full migration**\n- Remove `vehicles.home_location_id` column entirely\n- Update all code to use `vehicle_locations` table\n- More work but cleaner long-term\n\n## Affected Files\n\n- `src/services/vehicle.service.ts` - Vehicle save/update logic\n- `src/services/vehicle-location.service.ts` - Location association logic\n- `src/services/clustering.service.ts` - Uses `vehicle.homeLocationId`\n- `src/services/route-planning.service.ts` - Uses home locations for route planning\n\n## Acceptance Criteria\n\n- [ ] When a vehicle's primary location is set via UI, `vehicles.home_location_id` is updated\n- [ ] Existing routes continue to work\n- [ ] No manual database updates required for new vehicle locations\n\n---\n*Issue created via `/open-issue` command*","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZpg","name":"bug","description":"Something isn't working","color":"d73a4a"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":106,"title":"Sync vehicles.home_location_id with vehicle_locations primary entry"},{"body":"## Description\nThe legacy `service_id` column in the `bookings` table needs to be fully deprecated and eventually removed. While recent fixes in #87 have moved the route planner toward using `service_ids` (array) and `service_items` (JSONB), several core services still rely on the legacy field, leading to incorrect calculations and potential bugs for multi-service bookings.\n\n## Identified Dependencies\n- **RouteCostService**: Currently joins on `service_id` for revenue and materials cost calculations. This causes 0-value results for multi-service bookings.\n- **RouteGenerationService**: Uses `service_id` for batching/grouping bookings.\n- **ClusteringService**: Still checks `service_id` for vehicle compatibility checks.\n- **Frontend (Calendar/Bookings)**: Still uses `serviceId` as a fallback display property.\n\n## Tasks\n- [ ] Update `RouteCostService` to aggregate costs/revenue from `service_items` array instead of joining on `service_id`.\n- [ ] Refactor `RouteGenerationService` to group by `service_ids` or handle multi-service arrays in batches.\n- [ ] Update `ClusteringService` to exclusively use `service_ids` for compatibility checks.\n- [ ] Update frontend components (`calendar.html`, `bookings.html`) to use `service_items` for display.\n- [ ] Run final backfill of `service_ids` from `service_items` to ensure no data is lost.\n- [ ] Safe-drop the `service_id` column after confirming zero usage across the stack.\n\n---\n*Issue created via `/open-issue` command*","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":89,"title":"Deprecate legacy service_id column and migrate dependent services"},{"body":"## Problem\n\nThe customer edit form currently does not provide a way to manage tags for customers. While the database schema supports a `tags` text array field on the customers table, there is no UI to add, edit, or remove tags when editing a customer.\n\n## Current State\n\n- Customers table has a `tags` TEXT[] field in the database\n- Tags can only be set programmatically via direct database access or scripts\n- No UI component exists for tag management in the customer edit modal/form\n\n## Desired State\n\nUsers should be able to:\n- View existing tags on a customer in the edit form\n- Add new tags to a customer\n- Remove existing tags from a customer\n- Tags should be displayed as chips/badges with remove buttons\n- Input field should allow typing new tags (possibly with autocomplete of existing tags)\n\n## Acceptance Criteria\n\n- [ ] Customer edit form displays existing tags as visual chips/badges\n- [ ] Users can add new tags via an input field\n- [ ] Users can remove tags by clicking a remove button on each tag chip\n- [ ] Tags are saved to the database when the customer is updated\n- [ ] Tag input provides good UX (e.g., press Enter to add, autocomplete from existing tags)\n- [ ] Empty tag values are not allowed\n- [ ] Duplicate tags are prevented\n- [ ] Tags array is properly handled in the customer service layer\n\n## Technical Notes\n\n**Database Schema:**\n```sql\ntags TEXT[] -- Array of tags for categorization\n```\n\n**TypeScript Type:**\n```typescript\ninterface Customer {\n  // ... other fields\n  tags?: string[];\n}\n```\n\n**Files Likely to Modify:**\n- Customer edit form/modal UI component\n- Customer service/API handlers (if not already supporting tags)\n- Customer TypeScript types (already support tags)\n\n## Examples\n\nSimilar tag management UIs:\n- GitHub issue labels\n- Gmail labels\n- Tag input components in common UI libraries\n\n## Additional Context\n\nCurrently using tags for customer categorization (e.g., 'LL' tag for Lees Summit customers). This feature would make tag management accessible to all users without requiring database scripts.\n\n## Related Issues\n\n- #56 - Tag autocomplete suggestions (enhancement to this feature)\n\n---\n*Issue created via `/open-issue` command*","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":82,"title":"Add tag management to customer edit form"},{"body":"## Summary\n\nEnable adding, editing, and displaying tags on bookings to help categorize and filter bookings.\n\n## Requirements\n\n### Database Changes\n- [ ] Add `tags` column to `bookings` table (JSONB array or text array)\n- [ ] Consider creating a `booking_tags` junction table if tags need to be normalized/reusable\n- [ ] Add index for tag-based queries\n\n### Backend Changes\n- [ ] Update `Booking` type to include `tags` field\n- [ ] Update `CreateBookingInput` and `UpdateBookingInput` to support tags\n- [ ] Update booking service CRUD operations to handle tags\n- [ ] Add filtering by tags in `getBookings` (support filtering by multiple tags)\n\n### UI Changes - Edit Modal\n- [ ] Add tags input field to booking edit modal\n- [ ] Support adding new tags (free-form or from existing tags)\n- [ ] Support removing tags\n- [ ] Auto-complete/suggestions from existing tags in the system\n\n### UI Changes - Bookings Page\n- [ ] Display tags as badges/chips on each booking row\n- [ ] Color-code tags or allow custom tag colors (optional)\n\n### UI Changes - Tag Filter on Bookings Page\n- [ ] Add tag filter component to the bookings page filter bar\n- [ ] Support searching/selecting from existing tags in the system\n- [ ] Allow filtering by **one or more tags** (multi-select)\n- [ ] Filter should show bookings that match ANY of the selected tags (OR logic)\n- [ ] Clear visual indication of active tag filters\n- [ ] Easy way to clear tag filters\n\n## Use Cases\n\n1. **Service categorization**: Tag bookings as \"urgent\", \"recurring\", \"VIP\"\n2. **Workflow tracking**: Tag as \"needs-confirmation\", \"pending-payment\"\n3. **Grouping**: Tag by project, contract, or customer segment\n4. **Filtering**: Quickly find all \"VIP\" bookings or all \"urgent\" + \"pending-payment\" bookings\n\n## Technical Considerations\n\n- Tags should be case-insensitive for matching\n- Consider max tag length (e.g., 50 chars)\n- Consider max tags per booking (e.g., 10)\n- Reuse existing tag components if available from other features\n- Tag filter should query efficiently (indexed)\n\n## Acceptance Criteria\n\n- [ ] Can add tags when creating/editing a booking\n- [ ] Tags are visible on the bookings list page\n- [ ] Can filter bookings by one or more tags using the tag filter\n- [ ] Tag filter shows searchable list of existing tags\n- [ ] Tags persist correctly in the database","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":80,"title":"feat: Add tags support for bookings"},{"body":"## Problem\n\nCurrently using a single Google Maps API key for both server-side and browser-side operations. This causes issues:\n\n1. **HTTP referrer restrictions don't work with server-side APIs**\n   - Geocoding API, Places Autocomplete, and Distance Matrix API are called server-side\n   - Error: `API keys with referer restrictions cannot be used with this API`\n   - We cannot restrict the key to specific domains without breaking server-side functionality\n\n2. **Security vulnerability**\n   - If we use NO restrictions (to make server-side work), the key can be stolen from browser\n   - If we use HTTP referrer restrictions (to secure browser), server-side APIs fail\n\n## Current Usage\n\n**Server-side (Node.js backend):**\n- `src/services/googlemaps.service.ts`\n- Geocoding API: `https://maps.googleapis.com/maps/api/geocode/json`\n- Places Autocomplete API: `https://maps.googleapis.com/maps/api/place/autocomplete/json`\n- Distance Matrix API: `https://maps.googleapis.com/maps/api/distancematrix/json`\n\n**Browser-side (frontend):**\n- `web-launcher/public/routes.html` (line 965)\n- Maps JavaScript API: `https://maps.googleapis.com/maps/api/js`\n\n## Proposed Solution\n\nImplement a **two-key architecture**:\n\n### Key 1: Server-Side API Key\n**Purpose:** Backend API calls (geocoding, autocomplete, distance matrix)  \n**Environment Variable:** `GOOGLE_MAPS_API_KEY`  \n**Restrictions:**\n- Application restrictions: None (or IP-based if static IPs available)\n- API restrictions: Only Geocoding API, Places API, Distance Matrix API\n- Never exposed to browser\n\n### Key 2: Browser-Side API Key\n**Purpose:** Frontend map display  \n**Environment Variable:** `GOOGLE_MAPS_BROWSER_KEY` (new)  \n**Restrictions:**\n- Application restrictions: HTTP referrers\n  - `https://fleetillo.com/*`\n  - `https://*.fleetillo.com/*`\n  - `https://optiroute-web-tulrl.ondigitalocean.app/*`\n  - `http://localhost/*`\n  - `http://127.0.0.1/*`\n- API restrictions: Only Maps JavaScript API\n\n## Implementation Tasks\n\n### 1. Google Cloud Console Setup\n\n- [ ] Create new API key: \"Fleetillo Server-Side\"\n  - Set API restrictions: Geocoding API, Places API, Distance Matrix API\n  - Set application restrictions: None (or IP-based)\n  \n- [ ] Create/configure API key: \"Fleetillo Browser\"\n  - Set API restrictions: Maps JavaScript API only\n  - Set application restrictions: HTTP referrers (domains listed above)\n\n### 2. Backend Changes\n\n**File:** `src/config/index.ts`\n\nAdd new environment variable:\n```typescript\ngoogleMaps: {\n  apiKey: process.env.GOOGLE_MAPS_API_KEY,        // Server-side key\n  browserApiKey: process.env.GOOGLE_MAPS_BROWSER_KEY,  // Browser-side key (NEW)\n},\n```\n\n**File:** `src/services/googlemaps.service.ts`\n\nNo changes needed - continues using `config.googleMaps.apiKey` for server-side calls\n\n### 3. Frontend Changes\n\n**File:** `web-launcher/server.js`\n\nAdd endpoint to serve browser API key:\n```javascript\napp.get('/api/config', (req, res) => {\n  res.json({\n    googleMapsBrowserKey: process.env.GOOGLE_MAPS_BROWSER_KEY\n  });\n});\n```\n\n**File:** `web-launcher/public/routes.html` (line ~965)\n\nUpdate to fetch and use browser key:\n```javascript\n// Before:\nscript.src = `https://maps.googleapis.com/maps/api/js?key=${apiKey}&libraries=geometry`;\n\n// After:\nconst configResponse = await fetch('/api/config');\nconst config = await configResponse.json();\nscript.src = `https://maps.googleapis.com/maps/api/js?key=${config.googleMapsBrowserKey}&libraries=geometry`;\n```\n\n### 4. Environment Variables\n\n**Update in all environments:**\n\n**.env (local development):**\n```bash\nGOOGLE_MAPS_API_KEY=<server_side_key>\nGOOGLE_MAPS_BROWSER_KEY=<browser_side_key>\n```\n\n**DigitalOcean App Platform:**\n- fleetillo-app → Components → web → Environment Variables\n- Add: `GOOGLE_MAPS_BROWSER_KEY` (SECRET type)\n- Update: `GOOGLE_MAPS_API_KEY` (server-side key value)\n\n**primco-demo (if uses Google Maps):**\n- Check if it uses Google Maps\n- Update accordingly\n\n### 5. Documentation\n\n**File:** `deploy/SECRETS.md`\n\nUpdate to document both keys:\n```markdown\n#### `GOOGLE_MAPS_API_KEY` (Server-Side)\n- **Description**: Google Maps API key for server-side geocoding and places\n- **Restrictions**: API-only (Geocoding, Places, Distance Matrix)\n- **Where to configure**: DigitalOcean dashboard, .env file\n\n#### `GOOGLE_MAPS_BROWSER_KEY` (Browser-Side)\n- **Description**: Google Maps API key for frontend map display\n- **Restrictions**: HTTP referrers + Maps JavaScript API only\n- **Where to configure**: DigitalOcean dashboard, .env file\n```\n\n**File:** `deploy/GOOGLE_MAPS_API_RESTRICTION.md`\n\nUpdate to reflect two-key architecture\n\n### 6. Testing\n\n- [ ] **Local development:**\n  - Address search/autocomplete works\n  - Map displays correctly\n  - Geocoding works\n  - Distance matrix calculations work\n\n- [ ] **Production (fleetillo.com):**\n  - All above functionality works\n  - No API key errors in browser console\n\n- [ ] **Security verification:**\n  - Browser key cannot access Geocoding/Places APIs\n  - Server key works for all server-side APIs\n  - Browser key restricted to allowed domains\n\n## Success Criteria\n\n- [ ] Two separate API keys created with appropriate restrictions\n- [ ] Server-side APIs (geocoding, places, distance matrix) work without errors\n- [ ] Browser-side Maps JavaScript API works without errors\n- [ ] HTTP referrer restrictions active on browser key\n- [ ] API restrictions enforced on both keys\n- [ ] No `REQUEST_DENIED` errors in production\n- [ ] Documentation updated\n- [ ] All environments updated (local, staging, production)\n\n## Security Benefits\n\n1. **Browser key** can be stolen from browser → but it's restricted to:\n   - Specific domains only (can't be used elsewhere)\n   - Maps JavaScript API only (can't abuse geocoding/places)\n\n2. **Server key** never exposed to browser → protected from theft\n\n3. **Minimal API access** for each key → reduces attack surface\n\n## Related Issues\n\n- #75 (Pre-commit hook to prevent secrets in deployment files)\n- Recent security fixes removing hardcoded API keys from git\n\n## Priority\n\n**HIGH** - Currently cannot use HTTP referrer restrictions due to this limitation\n\n## Reference Documentation\n\n- Google Maps API Key Best Practices: https://developers.google.com/maps/api-security-best-practices\n- API Key Restrictions: https://cloud.google.com/docs/authentication/api-keys\n- Internal: `deploy/GOOGLE_MAPS_API_RESTRICTION.md`\n\n---\n*Issue created via Claude Code*","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"}],"number":76,"title":"Implement two-key Google Maps API configuration for server and browser"},{"body":"## Context\nThe current booking CSV import workflow strictly requires existing `customerId` and `locationId` UUIDs. This forces users to pre-create customers and locations before they can import bookings, which is inefficient for bulk onboarding or migrating data.\n\n## Requirement\nEnhance the Booking CSV upload workflow to support:\n1.  **New Customer Creation**: Allow users to provide Customer Name, Email, and Phone in the CSV. If the customer doesn't exist (e.g., lookup by email), create them on the fly.\n2.  **New Location Creation**: Allow users to provide full address details. If a `locationId` is not provided, use the address details to create a new location for the customer.\n\n## Technical Considerations\n-   **CSV Schema Expansion**: `csv.service.ts` needs to accept new columns for Customer and Location creation.\n-   **Resolution Logic**:\n    -   If `customerId` is provided -> Use it.\n    -   If `customerId` is empty -> Validate `Customer Name`/`Email`. Check if exists. If yes -> Use ID. If no -> Create new Customer.\n    -   Same logic applies to Locations.\n-   **Validation**: New entities must pass their respective validation rules.\n-   **Transactional Integrity**: The creation of Customer, Location, and Booking should happen within a transaction (or handle partial failures gracefully).\n\n## Acceptance Criteria\n-   CSV Template includes columns for Customer Name, Email, Phone, and Location Address.\n-   Upload creating a booking for a new customer works.\n-   Upload creating a booking for an existing customer at a new location works.\n-   Existing functionality (using UUIDs) remains supported.\n-   Proper error reporting if customer/location creation fails.\n\nThis is a high-priority usability enhancement requested by customers.","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":74,"title":"Enable creation of new Customers and Locations via Booking CSV Import"},{"body":"## Motivation\n\nIssue #57 revealed UI regressions in the Locations list and Edit Modal after the Client → Customer terminology refactor (#14). These regressions were not caught before merge:\n1. 'Client' pill still appearing in Locations list\n2. Customer name not populating in Edit Location modal\n\nThis indicates a gap in our testing strategy. We need automated regression testing to catch UI breaks before they reach production.\n\n## Problem Statement\n\n**Current State:**\n- Manual testing is inconsistent and time-consuming\n- UI changes across multiple pages can introduce regressions\n- No automated verification of form fields, modals, or interactive elements\n- Post-merge discoveries slow down development velocity\n\n**Goal:**\nResearch and implement a robust regression testing strategy that:\n1. Catches UI regressions automatically\n2. Runs on every PR before merge\n3. Covers critical user workflows\n4. Provides fast feedback to developers\n\n## Research Areas\n\n### 1. End-to-End (E2E) Testing Framework\n- [ ] **Playwright** (recommended in `.claude/rules/testing.md`)\n- [ ] Evaluate coverage needs for:\n  - Form interactions (create, edit, delete)\n  - Modal popups and field population\n  - List views and data display\n  - Navigation flows\n  - Data persistence across page refreshes\n\n### 2. Visual Regression Testing\n- [ ] **Percy** (visual snapshots)\n- [ ] **Chromatic** (Storybook integration)\n- [ ] **Playwright Screenshots** (built-in)\n- [ ] Capture baseline images for key pages\n- [ ] Detect unintended visual changes\n\n### 3. Component-Level Testing\n- [ ] **Testing Library** for React/vanilla JS components\n- [ ] Test form field bindings\n- [ ] Test modal open/close and data population\n- [ ] Test filter/search functionality\n\n### 4. CI/CD Integration\n- [ ] Run E2E tests on every PR\n- [ ] Parallel test execution for speed\n- [ ] Fail PR if tests fail (block merge)\n- [ ] Screenshot/video artifacts on failure\n- [ ] Performance budgets (test execution time)\n\n### 5. Test Data Management\n- [ ] Seed test database with realistic data\n- [ ] Reset database state between test runs\n- [ ] Mock external APIs (Google Places, Telegram)\n- [ ] Test isolation strategy\n\n### 6. Coverage Targets\n\n**Critical Paths (Must Test):**\n- [ ] Customer CRUD operations\n- [ ] Location CRUD operations (including customer assignment)\n- [ ] Booking/Route creation and assignment\n- [ ] Driver/Vehicle management\n- [ ] Calendar views (day, week, routes)\n- [ ] Dispatch workflow\n\n**Regression-Prone Areas:**\n- [ ] Terminology consistency (Customer vs Client)\n- [ ] Form field population in edit modals\n- [ ] Foreign key relationships (customer_id, location_id)\n- [ ] Tag/metadata display across views\n\n## Proposed Approach\n\n### Phase 1: Foundation (Immediate)\n1. Set up Playwright test infrastructure\n2. Write 5-10 critical path E2E tests\n3. Integrate with GitHub Actions\n4. Document test-writing guidelines\n\n### Phase 2: Expansion (Short-term)\n1. Add visual regression testing\n2. Expand coverage to 80%+ of user workflows\n3. Add component-level tests for complex interactions\n4. Performance monitoring\n\n### Phase 3: Optimization (Long-term)\n1. Parallel test execution\n2. Selective test running (only affected tests)\n3. Flaky test detection and remediation\n4. Test maintenance automation\n\n## Success Criteria\n\n- [ ] All critical user workflows have E2E test coverage\n- [ ] Tests run on every PR and block merge on failure\n- [ ] Tests complete in < 10 minutes\n- [ ] Visual regressions are detected automatically\n- [ ] No more UI regressions slip through to production\n\n## Related Issues\n\n- #57 - The regression that motivated this issue\n- #14 - Client → Customer refactor (source of regression)\n\n## Technical Notes\n\n- Existing test infrastructure: Jest for unit tests (see `.claude/rules/testing.md`)\n- Need to add Playwright for E2E tests\n- Consider using DigitalOcean preview environments for E2E test targets\n- Test data seeding strategy needed (see `test-data-policy` skill)\n\n---\n\n**Priority:** High - Quality foundation for future development\n**Type:** Research + Implementation\n**Estimated Complexity:** Complex (7-9 pts) - requires planning document","labels":[{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":68,"title":"Implement robust regression testing to prevent UI regressions"},{"body":"## Problem\nWhen a custom field definition is deleted from Settings, there is no protection for existing data:\n\n1. **Orphaned Data**: If you delete a custom field definition, the existing `metadata` values in location records remain in the database but become invisible and uneditable.\n\n2. **Silent Data Loss on Re-save**: When a user edits and saves a location after a custom field was deleted, the old field's value in metadata is **overwritten/removed** when the location is saved.\n\n3. **No Warning**: There's no confirmation dialog when deleting a custom field to warn that existing data might be affected.\n\n## Proposed Solution\n\n### Backend Changes\n- [ ] Add an API endpoint to check if a custom field key has existing values in locations\n  - Query: `SELECT COUNT(*) FROM locations WHERE metadata ? '${fieldKey}'`\n- [ ] Return count of locations with values for that field\n\n### Frontend Changes (settings.html)\n- [ ] Before allowing deletion of a custom field, call the API to check for existing values\n- [ ] If values exist, show a confirmation dialog:\n  - \"This custom field has values saved in X locations. Deleting it will make those values inaccessible. Are you sure?\"\n- [ ] Optionally: Offer to view/export the affected locations before deletion\n\n### Data Preservation (locations.html)\n- [ ] When saving a location, preserve any `metadata` keys that aren't in the current custom field definitions\n- [ ] This prevents accidental data loss if a field is temporarily removed\n\n## Acceptance Criteria\n- [ ] Cannot delete a custom field without confirmation if values exist\n- [ ] User sees count of affected locations before confirming deletion\n- [ ] Existing metadata values are preserved on location save even if field definition is missing\n\n## Related\n- Issue #16 - Original custom fields implementation","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":67,"title":"feat: Protect custom fields from deletion when values exist in locations"},{"body":"## Summary\n\nAdd autocomplete/typeahead functionality to all tag input fields in the application. When users start typing a tag, show suggestions from existing tags to promote consistency and prevent duplicate/similar tags.\n\n## Background\n\nIssue #41 (PR #54) added tag input UI to drivers and locations pages. During testing, we identified the need for autocomplete to:\n- Prevent creating duplicate tags (e.g., \"Urgent\" vs \"urgent\" vs \"URGENT\")\n- Help users discover existing tags\n- Improve data consistency across entities\n\n## Affected Pages\n\nAll pages with tag input functionality:\n- [ ] `customers.html` - Customer tags\n- [ ] `drivers.html` - Driver tags  \n- [ ] `locations.html` - Location tags\n- [ ] `vehicles.html` - Vehicle tags (if applicable)\n- [ ] Any future pages with tagging\n\n## Requirements\n\n### Functional\n1. **Typeahead suggestions**: As user types, show dropdown with matching tags\n2. **Case-insensitive matching**: \"urg\" matches \"Urgent\", \"URGENT\", \"urgent\"\n3. **Cross-entity suggestions**: Option to show tags from all entities or just current entity type\n4. **Keyboard navigation**: Arrow keys to navigate, Enter to select, Escape to dismiss\n5. **Click to select**: Mouse click on suggestion adds the tag\n6. **Create new option**: If no match, allow creating new tag (current behavior)\n\n### Non-Functional\n1. **Debounced search**: 200-300ms delay to avoid excessive API calls\n2. **Limit results**: Show max 8-10 suggestions\n3. **Performance**: Must handle 10,000+ tags without degradation\n4. **Responsive**: Dropdown should work on mobile\n\n## Technical Approach\n\n### Recommended: Server-Side Search\n\n```\nGET /api/rpc/tags.search?q=urg&entity=drivers&limit=10\n\nResponse:\n{\n  \"tags\": [\"Urgent\", \"ургентный\"],\n  \"total\": 2\n}\n```\n\n**Backend Implementation:**\n- Query across relevant tables (customers, drivers, locations, vehicles)\n- Use PostgreSQL `ILIKE` or full-text search\n- Return distinct tags sorted by frequency/relevance\n- Optional: Cache popular tags\n\n**Frontend Implementation:**\n- Create reusable `TagAutocomplete` component/function\n- Debounce input events\n- Render dropdown positioned below input\n- Handle keyboard and mouse interactions\n\n### Alternative: Shared Tags Table\n\nFor better scalability and tag management:\n\n```sql\nCREATE TABLE tags (\n  id UUID PRIMARY KEY,\n  name TEXT UNIQUE NOT NULL,\n  usage_count INTEGER DEFAULT 0,\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n```\n\nThis would enable:\n- Tag usage analytics\n- Tag management UI (rename, merge, delete)\n- Faster autocomplete queries\n\n**Note**: This is a larger architectural change and could be a separate issue.\n\n## UI/UX Design\n\n```\n┌─────────────────────────────────────┐\n│ Tags                                │\n│ ┌─────────────────────────────────┐ │\n│ │ [Urgent ×] [VIP ×]  urg█        │ │\n│ └─────────────────────────────────┘ │\n│ ┌─────────────────────────────────┐ │\n│ │ Urgent                      (5) │ │  ← suggestion with count\n│ │Ургентный                   (2) │ │\n│ │ ─────────────────────────────── │ │\n│ │ + Create \"urg\"                  │ │  ← create new option\n│ └─────────────────────────────────┘ │\n└─────────────────────────────────────┘\n```\n\n## Acceptance Criteria\n\n- [ ] Typing in any tag input shows relevant suggestions\n- [ ] Suggestions appear after 2+ characters typed\n- [ ] Suggestions load within 200ms\n- [ ] Can navigate suggestions with keyboard\n- [ ] Can select suggestion with Enter or click\n- [ ] Escape dismisses suggestions\n- [ ] Works on all pages with tag inputs\n- [ ] No duplicate tags created due to case differences\n- [ ] Performance acceptable with 10,000+ existing tags\n\n## Dependencies\n\n- #41 - Tag UI for drivers and locations (merged)\n\n## Related\n\n- PR #40 - Added tags column to drivers and locations tables\n- PR #54 - Added tag UI (this enhancement builds on it)\n\n## Notes\n\nConsider implementing as a reusable JavaScript module that can be applied to any tag input field with minimal configuration:\n\n```javascript\n// Example usage\nsetupTagAutocomplete({\n  inputId: 'driver-tag-input',\n  chipsContainerId: 'driver-tag-chips',\n  entityType: 'drivers', // for scoped suggestions\n  onTagsChange: (tags) => { currentDriverTags = tags; }\n});\n```","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":56,"title":"feat: Tag autocomplete suggestions across all tagging UIs"},{"body":"## Summary\n\nEnable automatic issue triage when new issues are created or updated in the repository. A DigitalOcean function will receive GitHub webhook events and apply complexity labels without manual intervention.\n\n## Motivation\n\nCurrently, issue triage requires running `/issue-check` manually to analyze and label new issues. This creates delays in the workflow and requires human intervention. Automating this process ensures:\n- New issues are immediately categorized\n- Contributors see complexity labels faster\n- The backlog stays organized without manual effort\n\n## Proposed Architecture\n\n```\nGitHub Issue Created/Updated\n         ↓\n   GitHub Webhook\n         ↓\n  DigitalOcean Function\n         ↓\n   AI Model Analysis\n         ↓\n  GitHub API: Apply Labels + Comment\n```\n\n### Components\n\n#### 1. GitHub Webhook Configuration\n- **Events**: `issues` (opened, edited, reopened)\n- **Target**: DigitalOcean Function HTTP endpoint\n- **Secret**: Webhook signature validation\n\n#### 2. DigitalOcean Function\n- **Runtime**: Node.js or Python\n- **Trigger**: HTTP (webhook receiver)\n- **Tasks**:\n  1. Validate webhook signature\n  2. Skip if issue already has triage labels\n  3. Extract issue title, body, labels\n  4. Call AI model for complexity analysis\n  5. Apply appropriate label via GitHub API\n  6. Post assessment comment\n\n#### 3. AI Model Options\n\n**Option A: DigitalOcean GenAI (Recommended)**\n- Use DO's built-in AI models (no external API keys needed)\n- Simpler deployment within DO ecosystem\n- Cost-effective for lightweight analysis\n\n**Option B: Anthropic API**\n- Use Claude Haiku for fast, cheap analysis\n- Requires API key management\n- More sophisticated reasoning capabilities\n\n**Option C: GitHub Copilot API**\n- Native GitHub integration\n- May have rate limits for automation\n\n### Complexity Scoring Prompt\n\nThe function should score issues on these factors (0-2 pts each):\n| Factor | 0 pts | 1 pt | 2 pts |\n|--------|-------|------|-------|\n| Files affected | 1-2 | 3-5 | 6+ |\n| Architecture | None | Minor | Major |\n| Database | None | Column | Tables |\n| API changes | None | Modify | New |\n| External integration | None | Existing | New |\n| Security | None | Validation | Auth |\n| Requirements clarity | Clear | Flexible | Vague |\n\n**Labels:**\n- 0-2 pts → `plan: simple`\n- 3-6 pts → `plan: medium`\n- 7+ pts → `plan: complex`\n\n## Implementation Tasks\n\n### Setup\n- [ ] Create DigitalOcean function project\n- [ ] Configure function with appropriate runtime\n- [ ] Set up environment variables (GitHub token, webhook secret)\n\n### Function Logic\n- [ ] Webhook signature validation\n- [ ] Issue payload parsing\n- [ ] Skip logic for already-triaged issues\n- [ ] AI model integration for analysis\n- [ ] GitHub API calls for labeling and commenting\n\n### GitHub Configuration\n- [ ] Create webhook in repository settings\n- [ ] Point to DO function endpoint\n- [ ] Configure secret for validation\n\n### Testing\n- [ ] Test with sample issue payloads\n- [ ] Verify label application\n- [ ] Verify comment posting\n- [ ] Test skip logic for existing labels\n\n## Security Considerations\n\n- [ ] Webhook signature validation (HMAC-SHA256)\n- [ ] GitHub token with minimal scopes (issues:write only)\n- [ ] Rate limiting to prevent abuse\n- [ ] Error handling without exposing secrets\n\n## Open Questions\n\n1. **AI Model Selection**: Should we use DigitalOcean's GenAI models or an external provider?\n2. **Codebase Context**: Does the function need to search the codebase, or can it triage based on issue text alone?\n3. **Re-triage**: Should editing an issue trigger re-analysis, or only new issues?\n\n## Related\n\n- Current manual process: `/issue-check` skill\n- Existing DO functions: `dispatch-poller`, scheduled jobs\n- Issue #13 (log monitoring) - similar DO function pattern","labels":[{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":47,"title":"Automated issue triage via DigitalOcean function on GitHub webhook"},{"body":"## Overview\nIntroduce a modern bundler (Vite or Webpack) for the frontend codebase to improve developer experience, enable ES modules, and optimize production builds.\n\n## Background\nIssue #21 refactors the frontend to use `api-client.js` with a \"bundle-ready\" structure (no circular dependencies, clear entry points). This issue builds on that foundation to introduce proper bundling.\n\n## Benefits\n\n### Developer Experience\n- Hot module replacement (HMR)\n- Source maps for debugging\n- TypeScript support (optional)\n- Import/export syntax\n\n### Production\n- Tree-shaking (remove unused code)\n- Minification\n- Code splitting\n- Cache busting\n\n## Proposed Approach: Vite\n\nVite is recommended over Webpack because:\n- Faster development server (native ES modules)\n- Simpler configuration\n- Built-in support for common patterns\n- Easy migration from script tags\n\n## Scope\n\n### Setup\n- [ ] Add `vite` and dependencies to package.json\n- [ ] Create `vite.config.js`\n- [ ] Configure build output to match current `public/` structure\n\n### Migration\n- [ ] Convert `config.js` and `api-client.js` to ES modules\n- [ ] Update HTML files to use module script tags\n- [ ] Update deployment scripts\n\n### Verification\n- [ ] Development server works\n- [ ] Production build works\n- [ ] All existing functionality preserved\n\n## Dependencies\n- Depends on #21 (Electron dependency refactor)\n- Optional dependency on #27 (folder consolidation)\n\n## Notes\nThis is a non-urgent enhancement. The current script tag approach works fine; this adds optimization and DX improvements.","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":28,"title":"Introduce Vite/Webpack bundler for frontend assets"},{"body":"## Overview\nEnable the API layer to be deployed and scaled independently from the frontend static assets.\n\n## Background\nThis issue is a follow-up to #21 (Refactor Frontend to Remove Electron Dependency). Issue #21 will establish the **foundation** for API scalability by:\n- Creating a configurable API base URL in `api-client.js`\n- Using proper fetch patterns with credentials handling\n- Clean module separation\n\nThis issue handles the **infrastructure and backend changes** needed to actually deploy the API separately.\n\n## Scope\n\n### Backend Changes\n- [ ] Add CORS headers to all API endpoints\n- [ ] Configure allowed origins (environment-based)\n- [ ] Ensure authentication works cross-origin (cookies with SameSite or JWT tokens)\n\n### Infrastructure Changes\n- [ ] Create separate DigitalOcean App Platform service for API\n- [ ] Configure CDN/static hosting for frontend (or keep in same service initially)\n- [ ] Environment configuration for API_BASE_URL per environment\n- [ ] Update deployment scripts/app spec\n\n### Configuration\n- [ ] Environment variable: `API_BASE_URL`\n- [ ] CORS allowed origins configuration\n- [ ] Document deployment architecture\n\n## Acceptance Criteria\n1. Frontend can be served from a different origin than the API\n2. API can scale horizontally (multiple instances)\n3. Authentication continues to work correctly\n4. All existing functionality preserved\n\n## Dependencies\n- Depends on #21 (foundation work)\n\n## Notes\nThis enables future architecture where:\n- **Frontend** → CDN/static hosting (fast, global)\n- **API** → Horizontally scalable backend service (DigitalOcean App Platform with auto-scaling)","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":26,"title":"API Layer Scalability: Separate Backend for Horizontal Scaling"},{"body":"## Summary\n\nEnable deployment of the Fleetillo database schema to different schema names, supporting multi-tenant or environment-specific deployments.\n\n## Background\n\nDuring the Issue #14 migration (clients → customers, routeiq → fleetillo), we identified that:\n- The migration script has hardcoded schema name ('fleetillo')\n- Grants need to be applied manually after schema creation\n- No automated validation of schema structure exists\n\n## Requirements\n\n### Deployment Script\n- [ ] Create parameterized schema deployment script\n- [ ] Accept schema name as parameter (default: 'fleetillo')\n- [ ] Automatically apply necessary grants for Supabase roles (anon, authenticated, service_role)\n- [ ] Include post-deployment validation step\n\n### Migration Support\n- [ ] Template the consolidated migration script to accept schema name variable\n- [ ] Document how to deploy to a new schema\n\n### Validation\n- [ ] Integrate schema validation into deployment process\n- [ ] Verify all tables, columns, and constraints exist\n- [ ] Verify RLS policies are applied\n\n## Example Usage\n\n```bash\n# Deploy to default schema\n./scripts/deploy-schema.sh\n\n# Deploy to custom schema name\n./scripts/deploy-schema.sh --schema customer_abc\n\n# Validate existing schema\n./scripts/deploy-schema.sh --validate-only --schema fleetillo\n```\n\n## Dependencies\n\n- Blocked by: Issue #14 (clients → customers migration)\n\n## Notes\n\n- Current workaround: manually edit schema name in migration SQL and run grants separately\n- Validation script exists at `scripts/validate-fleetillo-schema.ts` (can be adapted)\n","labels":[{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"}],"number":23,"title":"Add parameterized schema deployment support"},{"body":"## Goal\nIdempotently load parsed CSV data into the database.\n\n## Source Data Summary\n- **Customers (Brands)**: 278 records (e.g., \"Applebee's\", \"Bojangles\")\n- **Locations (Sites)**: 870 records\n- **Bookings**: 1,193 service records\n\n## Tasks\n\n### 1. Order of Operations\n```\n1. Customers - 278 brand records (e.g., \"Applebee's\", \"Bojangles\")\n   ↓\n2. Locations - 870 site records, each linked to ONE customer via customer_id\n   ↓\n3. Bookings - 1,193 service records, each linked to ONE location via location_id\n```\n\n**Relationship Enforcement:**\n- Each Location MUST have a valid `customer_id` (FK to customers)\n- Each Booking MUST have a valid `location_id` (FK to locations)\n- Never create duplicate customers for the same brand\n- Never create duplicate locations for the same customer+site\n\n### 2. Idempotency Strategy\n- [ ] **Customer Matching**: By normalized name (e.g., \"APPLEBEES\")\n- [ ] **Location Matching**:\n  - Primary: `customer_id` + `address_hash` (SHA256 of normalized address)\n  - Secondary: `customer_id` + geospatial check (within 50m)\n- [ ] **Booking Matching**: By `crm_id` (unique constraint prevents duplicates)\n- [ ] **CRM ID Generation**:\n  ```\n  crm_id = SHA256(customer + \"|\" + location + \"|\" + date + \"|\" + driver)\n  Example: SHA256(\"DKW-Bojangles #542|1045 S Lake Blvd...|2026-01-01|Amari Dinkins\")\n  ```\n\n### 3. Update Logic\n- [ ] **Locations**: If exists, merge location requirements into `metadata` (don't overwrite verified coordinates or existing non-empty metadata values), add 'Imported' tag\n- [ ] **Bookings**: Skip if `crm_id` already exists\n\n### 4. Booking Generation\n- [ ] **Date Mapping**: `Job/Est Date` → `bookings.scheduled_date`\n- [ ] **Status Mapping**:\n  | CSV Status | App Status | CRM Status | Notes |\n  |------------|------------|------------|-------|\n  | `Scheduled` | `confirmed` | SCHEDULED | Ready for routing |\n  | `Dispatched` | `scheduled` | DISPATCHED | Assigned but not sent to driver |\n  | `Closed and Complete` | `completed` | COMPLETED | Historical record |\n  | `Completed` | `completed` | COMPLETED | Historical record |\n- [ ] **Historical Bookings**: For `completed` status, also set `actual_start_time` = `scheduled_date`\n- [ ] **Service Type**: Always link to `GT-PUMP` service\n- [ ] **Driver Attribution**: For historical bookings, assign matched `driver_id` if available\n\n## Acceptance Criteria\n- [ ] Exactly 278 customers created (no duplicates on re-run)\n- [ ] Exactly 870 locations created, each linked to correct customer\n- [ ] All 1,193 bookings created with correct status and location linkage\n- [ ] Re-running import creates 0 new records (idempotent)\n- [ ] Spot check: \"Applebee's\" customer has exactly 30 locations\n- [ ] Spot check: \"Bojangles\" customer has exactly 222 locations\n- [ ] Locations tagged 'Needs Review' have clear issues logged\n\n## Dependencies\n- [ ] #15 Schema enhancements\n- [ ] #18 CSV Parser\n\n---\n📋 Part of Data Import Modernization Plan - see `docs/data_import_modernization_plan.md`","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":19,"title":"feat: Database Upsert & Booking Generation for legacy import"},{"body":"## Overview\nEnable users to select which custom fields appear as columns in the locations table. The current implementation already displays tags, but lacks support for showing custom field metadata (capacity, trap count, service frequency, etc.) as table columns.\n\n## Current State\n- ✅ **Tags column**: Already implemented and working\n- ❌ **Custom field columns**: No mechanism to display custom fields (metadata) as table columns\n- ❌ **Column configuration**: No UI to select which fields to display\n\n## Problem Statement\nCustom fields are defined in Settings and stored in `locations.metadata` (JSONB), but there's no way to surface this data in the locations table view. Users need to:\n1. Choose which custom fields to display as columns\n2. Have guardrails to prevent too many columns (avoid horizontal scrolling)\n3. See a clean, consistent table experience\n\n## Research-Based Solution\n\n### Best Practices (2026 UX Standards)\nBased on research of modern data table patterns:\n- **Column limits**: 6-8 columns optimal for readability without horizontal scrolling\n- **Column selector**: Dropdown or modal with checkboxes for toggling visibility\n- **Visual feedback**: Show column count (e.g., \"3 of 4 custom columns selected\")\n- **Saved preferences**: Configuration persists across sessions\n- **Type-aware rendering**: Different field types display appropriately (numbers with suffix, booleans as ✓/✗)\n\n### Proposed Implementation\n**Max custom columns**: 4 additional columns (total 11: 7 fixed + 4 custom)\n\n**Column selector UI**:\n- Gear icon (⚙️) in table header\n- Dropdown with checkboxes for each custom field\n- Counter showing \"X of 4 selected\" with warning at 3/4\n- Disable checkboxes when limit reached\n- Reset and Apply buttons\n\n**Settings storage**: New setting `locations.tableColumns`\n```json\n{\n  \"visibleCustomFields\": [\"capacity_gallons\", \"trap_count\"]\n}\n```\n\n## Tasks\n\n### Phase 1: MVP\n- [ ] Add type definition for `locations.tableColumns` setting (`src/types/settings.ts`)\n- [ ] Create column selector UI component (gear icon + dropdown)\n- [ ] Implement checkbox list with custom field options\n- [ ] Add column limit enforcement (max 4 custom columns)\n- [ ] Implement save/load column preferences\n- [ ] Dynamically render table headers based on selected fields\n- [ ] Implement custom field cell rendering with type-aware formatting:\n  - `number`: Show with suffix (e.g., \"500 gallons\")\n  - `boolean`: Show as ✓ or ✗\n  - `text/select`: Plain text\n  - `null/empty`: Show as \"-\"\n\n### Phase 2: Polish (Optional Enhancement)\n- [ ] Add field type badges to column selector\n- [ ] Add tooltips explaining column limit\n- [ ] Smooth animations for dropdown\n- [ ] Toast notifications for save success/error\n- [ ] Keyboard navigation and accessibility\n\n### Phase 3: Future Enhancements\n- [ ] Column reordering (drag-and-drop)\n- [ ] Saved views (multiple column configurations)\n- [ ] Per-user preferences (vs. global setting)\n\n## Acceptance Criteria\n- [ ] Tags column is visible (already done ✓)\n- [ ] Gear icon opens column selector dropdown\n- [ ] User can select up to 4 custom fields to display as columns\n- [ ] Selected columns persist across page reloads\n- [ ] Table dynamically adds/removes columns based on selection\n- [ ] Custom field values format correctly by type\n- [ ] Limit of 4 custom columns is enforced with visual feedback\n- [ ] Table remains readable without horizontal scrolling\n\n## Dependencies\n- [x] #15 Schema enhancements (completed - metadata JSONB column exists)\n- [x] #16 Location forms metadata (completed - custom fields defined in settings)\n\n## Technical Details\n**Files to modify**:\n- `web-launcher/public/locations.html` - Column selector UI + dynamic table rendering\n- `src/types/settings.ts` - Add `LocationTableColumnConfig` interface\n\n**Settings structure**:\n- `locations.customFields` (existing) - Array of CustomFieldDefinition\n- `locations.tableColumns` (new) - Column visibility configuration\n\n**Research sources**:\n- [Data Table Design UX Patterns - Pencil & Paper](https://www.pencilandpaper.io/articles/ux-pattern-analysis-enterprise-data-tables)\n- [Designing Table Column Customization - Andrew Coyle](https://coyleandrew.medium.com/customize-columns-table-ui-pattern-b3a5a8d49701)\n- [Table UI for Large Datasets - Andrew Coyle](https://www.andrewcoyle.com/blog/table-ui-considerations-for-large-datasets)\n\n---\n📋 Part of Data Import Modernization Plan - see `docs/data_import_modernization_plan.md`","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrpw","name":"plan: medium","description":"Medium (3-6 pts) - needs plan.md document","color":"FBCA04"},{"id":"LA_kwDOQyPtOs8AAAACVmuH8Q","name":"needs review","description":"","color":"aaaaaa"}],"number":17,"title":"feat: Enhanced Location Lists & Customer Detail Views"},{"body":"## Enhancement Description\n\nImplement an automated workflow that monitors DigitalOcean App Platform runtime logs to proactively detect errors, anomalies, and potential bugs before they're reported by users.\n\n## Motivation\n\nDuring a recent debugging session, critical information about a dispatch failure was found in the DigitalOcean runtime logs - including the exact sequence of events that caused the bug:\n- Telegram registration success followed by form submission that wiped the data\n- 302 redirect errors from Telegram webhook\n- Invalid API key errors for email fallback\n\nThis information was only discovered through manual log inspection. An automated monitoring system could have detected these issues immediately.\n\n## Proposed Features\n\n### 1. Log Monitoring Agent\n- Periodically fetch runtime logs from DigitalOcean using the MCP integration\n- Parse structured JSON logs from the dispatch service\n- Identify error patterns and anomalies\n\n### 2. Error Pattern Detection\n- `level: \"error\"` - Any error-level log entries\n- `level: \"warn\"` with high frequency - Repeated warnings\n- HTTP 4xx/5xx responses in sequence\n- Known error signatures (e.g., \"chat not found\", \"API key is invalid\")\n\n### 3. Automated Actions\n- **Alert**: Send notification (Slack, email, or in-app) when errors detected\n- **Issue Creation**: Automatically create GitHub issues for recurring or critical errors\n- **Correlation**: Link related errors together (e.g., dispatch failure → telegram error → email fallback error)\n\n### 4. Log Retention & Analysis\n- Store parsed log summaries in Supabase for historical analysis\n- Track error frequency over time\n- Identify regression patterns after deployments\n\n## Technical Approach\n\n### Option A: Scheduled Job\nAdd a new DigitalOcean scheduled job (like dispatch-poller) that:\n1. Calls `doctl apps logs` or DigitalOcean API\n2. Parses and analyzes log content\n3. Stores findings and triggers alerts\n\n### Option B: Log Forwarding\nConfigure DigitalOcean log forwarding to:\n1. External log aggregator (Datadog, Papertrail, etc.)\n2. Custom webhook endpoint for processing\n3. Supabase edge function for real-time analysis\n\n### Option C: AI-Assisted Analysis\nUse the existing AI assistant infrastructure to:\n1. Periodically review logs via MCP integration\n2. Apply pattern recognition for anomaly detection\n3. Generate human-readable summaries and recommendations\n\n## Acceptance Criteria\n\n- [ ] Errors are detected within 15 minutes of occurrence\n- [ ] Critical errors trigger immediate notifications\n- [ ] Recurring errors auto-create GitHub issues with log context\n- [ ] Dashboard shows error trends and health status\n- [ ] False positive rate is manageable (< 10%)\n\n## Related\n\n- DigitalOcean MCP integration already available\n- Current log sources: web service, dispatch-poller, end-of-day jobs\n- Issue #12 could have been detected automatically with this system","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":13,"title":"Automated DigitalOcean log monitoring for proactive bug detection"},{"body":"## Summary\n\nEnhance the OptiRoute AI Assistant (gradient-agents integration) to detect when users are reporting bugs, requesting help with errors, or suggesting enhancements, and automatically create GitHub issues on their behalf with status tracking.\n\n## User Story\n\nAs a user interacting with the OptiRoute Assistant, I want to be able to describe a problem, bug, or feature request in natural language, and have the assistant:\n1. Recognize my intent to submit a support request\n2. Gather necessary details through conversation\n3. Create a well-formatted GitHub issue automatically\n4. Provide me with status updates on my submitted issues\n\n## Proposed Functionality\n\n### Intent Detection\nThe assistant should recognize phrases like:\n- \"I found a bug...\"\n- \"This isn't working correctly...\"\n- \"Can you submit this as an issue?\"\n- \"I'd like to request a feature...\"\n- \"There's an error when I...\"\n\n### Issue Creation Flow\n1. **Classify the request**: Bug, Error, or Enhancement\n2. **Gather details**:\n   - Clear description of the issue/request\n   - Steps to reproduce (for bugs)\n   - Expected vs actual behavior\n   - Screenshots or context if available\n3. **Draft the issue**: Show user a preview before submitting\n4. **Create via GitHub API**: Submit to the optiroute repository\n5. **Confirm**: Provide issue link and number to user\n\n### Status Updates\n- User can ask: \"What's the status of my issue #X?\"\n- Assistant retrieves issue state, comments, and labels\n- Summarizes progress in conversational format\n\n## Technical Considerations\n\n- Requires GitHub API integration (personal access token or GitHub App)\n- May need to extend the assistant's tool capabilities\n- Consider rate limiting and authentication handling\n- Store mapping of user conversations to created issues\n\n## Acceptance Criteria\n\n- [ ] Assistant can detect support request intent\n- [ ] Assistant can create issues with appropriate labels (bug, enhancement, etc.)\n- [ ] Assistant shows draft before submitting\n- [ ] Assistant provides issue link after creation\n- [ ] Assistant can query and report issue status\n- [ ] Issues are well-formatted with all relevant context\n\n## Related\n\n- Current assistant implementation in `web-launcher/` integration with gradient-agents","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":10,"title":"AI Assistant: Enable support request handling via GitHub Issues"},{"body":"To prepare for production deployment a full security audit is necessary to determine what tasks should be created to address critical and moderate security vulnurabilities.","labels":[{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":8,"title":"Security Audit January 2026"},{"body":"I need a way to geofence vehicles so that when they are assigned to a route, they are constrained by their geofence.","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"},{"id":"LA_kwDOQyPtOs8AAAACVmuH8Q","name":"needs review","description":"","color":"aaaaaa"}],"number":3,"title":"vehicle geofencing"},{"body":"I need a telegram messaging template system so that I can update the text that is sent for the dispatches.","labels":[{"id":"LA_kwDOQyPtOs8AAAACT1HZqg","name":"enhancement","description":"New feature or request","color":"a2eeef"},{"id":"LA_kwDOQyPtOs8AAAACVSanYg","name":"plan ready","description":"Planning complete - ready for implementation","color":"0052CC"},{"id":"LA_kwDOQyPtOs8AAAACVTMrzw","name":"plan: complex","description":"Complex (7+ pts) - needs requirements.md, design.md, tasks.md","color":"D93F0B"}],"number":2,"title":"messaging templates"}]
